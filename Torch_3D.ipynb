{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "################################################################################\n",
    "ML_Type = 'Class'\n",
    "Gene_Type = 'Common'\n",
    "Feature_Size = 2100  # Feature size {50, 100, 200, 400, 600, 800, 1000}\n",
    "print(ML_Type)\n",
    "print(Gene_Type)\n",
    "#print(\"Size of the Columns/Features is: %d.\" %(Feature_Size))\n",
    "dataDir = 'E:/1st Project/'\n",
    "dataDir = dataDir + str(ML_Type) + '/' + str(Gene_Type) + '/' + str(Feature_Size) + '/'\n",
    "outputDir = dataDir\n",
    "dataType = '';\n",
    "print(dataDir)\n",
    "################################################################################\n",
    "indx = 1\n",
    "print(indx)\n",
    "prt1 = 'X_orig_'+str(indx)+'.csv'\n",
    "prt2 = 'X_ko1_'+str(indx)+'.csv'; prt3 = 'X_ko2_'+str(indx)+'.csv'; prt4 = 'X_ko3_'+str(indx)+'.csv'\n",
    "prt5 = 'X_ko4_'+str(indx)+'.csv'; prt6 = 'X_ko5_'+str(indx)+'.csv';\n",
    "prt7 = 'Y_'+str(indx)+'.csv'; prt8 = 'Beta_'+str(indx)+'.csv';\n",
    "#prt9 = 'Pheno_Data' + '.csv';\n",
    "output_path1 = dataDir + prt1\n",
    "output_path2 = dataDir + prt2; output_path3 = dataDir + prt3; output_path4 = dataDir + prt4;\n",
    "output_path5 = dataDir + prt5; output_path6 = dataDir + prt6;\n",
    "output_path7 = dataDir + prt7; output_path8 = dataDir + prt8\n",
    "#output_path9 = dataDir + prt9\n",
    "\n",
    "X_orig = pd.read_csv(output_path1, header = None).values.astype(np.float32);\n",
    "X_ko1 = pd.read_csv(output_path2, header = None).values.astype(np.float32);\n",
    "X_ko2 = pd.read_csv(output_path3, header = None).values.astype(np.float32);\n",
    "X_ko3 = pd.read_csv(output_path4, header = None).values.astype(np.float32);\n",
    "X_ko4 = pd.read_csv(output_path5, header = None).values.astype(np.float32);\n",
    "X_ko5 = pd.read_csv(output_path6, header = None).values.astype(np.float32);\n",
    "Y = pd.read_csv(output_path7, header = None).values.astype(np.float32);\n",
    "Beta = pd.read_csv(output_path8, header = None).values.astype(np.float32);\n",
    "#Pheno = pd.read_csv(output_path9, header = None).values.astype(np.float32);\n",
    "\n",
    "print(\"Size of the original feature is: %d x %d.\" %(X_orig.shape))\n",
    "print(\"Size of the knockoff feature is: %d x %d.\" %(X_ko4.shape))\n",
    "print(\"Size of the target is: %d x %d.\" %(Y.shape))\n",
    "print(\"Size of the output weight is: %d x %d.\" %(Beta.shape))\n",
    "\n",
    "X_all = np.concatenate((X_orig,X_ko1),axis=1);\n",
    "Num_knock = 1;\n",
    "bias = True;\n",
    "validation_split = 0.1\n",
    "n = X_all.shape[0];\n",
    "X_dim = X_all.shape[1];\n",
    "\n",
    "####################################################\n",
    "num_epochs = 5;\n",
    "\n",
    "seed = 999\n",
    "np.random.seed(seed)\n",
    "\n",
    "num_row = X_all.shape[0];\n",
    "X_dim = X_all.shape[1];\n",
    "x3D_all = np.zeros((num_row, X_orig.shape[1] , Num_knock+1));\n",
    "x3D_all[:, :, 0] = X_orig;\n",
    "x3D_all[:, :, 1] = X_ko1; \n",
    "\n",
    "\n",
    "def Normalize(data, mean_data =None, std_data =None):\n",
    "    if not mean_data:\n",
    "        mean_data = np.mean(data)\n",
    "    if not std_data:\n",
    "        std_data = np.std(data)\n",
    "    norm_data = (data-mean_data)/std_data\n",
    "    return norm_data, mean_data, std_data\n",
    "\n",
    "num_row = X_orig.shape[0];\n",
    "x3D_all = np.zeros((num_row, X_orig.shape[1] , Num_knock+1));\n",
    "x3D_all[:, :, 0] = X_orig;\n",
    "x3D_all[:, :, 1] = X_ko1; \n",
    "x3D_all.shape\n",
    "\n",
    "del X_ko1\n",
    "\n",
    "x3D_all = (x3D_all-np.mean(x3D_all))/np.std(x3D_all);\n",
    "\n",
    "Kernel_Size = 1\n",
    "STRIDE = 1\n",
    "############ Zero-Padding ###############################\n",
    "print(f'The kernel size or number of neurons per group is: {Kernel_Size}')\n",
    "Var_dim = x3D_all[:, :, 0].shape[1]\n",
    "print(f'The total number of dimensions is: {Var_dim}')\n",
    "res = Var_dim%Kernel_Size\n",
    "print(f'The residual is: {res}')\n",
    "\n",
    "Num_group = int(x3D_all.shape[1]/STRIDE); \n",
    "Size_group1 = Num_group*Kernel_Size\n",
    "print(f'The total size of neurons for first locally connected layer is: {Size_group1}')\n",
    "\n",
    "print(f'number of features/columns after zero padding: {x3D_all.shape[1]}')\n",
    "#########################################################\n",
    "pVal = x3D_all.shape[1];\n",
    "Num_instance = x3D_all.shape[0];\n",
    "seed = 457\n",
    "bias = True;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3D_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_net.py\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "Y = torch.from_numpy(Y)\n",
    "x3D_all2 = torch.from_numpy(x3D_all)\n",
    "x3D_all2.requires_grad=True\n",
    "type(x3D_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_channels: The size of the new dimension is called the number of output channels, or number of output feature maps\n",
    "# In case of an RGB image, the size of the new dimension (aside from the width/height of the image) is 3.\n",
    "#This \"size of the 3rd dimension\" is called the number of input channels or number of input feature maps.\n",
    "#In the above image example, the number of input channels is 3, and we have a 3×3×3 kernel.\n",
    "#(in_channels=2,out_channels=1,output_size=98,kernel_size=1,stride=1)\n",
    "\n",
    "import torch.nn as nn\n",
    "class LocallyConnected1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, output_size, kernel_size, stride, bias=False):\n",
    "        super(LocallyConnected1d, self).__init__()\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.randn(1, out_channels, in_channels, output_size, kernel_size)\n",
    "        )\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(\n",
    "                torch.randn(1, out_channels, output_size)\n",
    "            )\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #_, c, h = x.size()\n",
    "        _,c, h = x.size()\n",
    "#        print(c)\n",
    "#        print(h)\n",
    "        kh = self.kernel_size\n",
    "        print(kh)\n",
    "        dh = self.stride\n",
    "        print(dh)\n",
    "        #x = x.unfold(2, kh, dh)\n",
    "        x = x.unfold(1, kh, dh)\n",
    "        print(x.shape)\n",
    "        # x = x.contiguous().view(*x.size()[:-2], -1)\n",
    "        # Sum in in_channel and kernel_size dims\n",
    "        x = x.unsqueeze(1)\n",
    "        out = (x * self.weight)\n",
    "        out = out.sum([2, -1])\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import BCELoss, Linear, Module, ReLU, Sigmoid\n",
    "from torch.nn.init import kaiming_uniform_, xavier_uniform_\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 2048\n",
    "input_size = 98\n",
    "input_size2 = 98\n",
    "hidden_size = 20\n",
    "learning_rate = 0.001\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.loc1 = LocallyConnected1d(2,1,input_size,1,1)\n",
    "        xavier_uniform_(self.loc1.weight)\n",
    "        self.ActLoc1 = torch.nn.functional.elu\n",
    "        self.fc1 = nn.Linear(input_size2, hidden_size) \n",
    "        xavier_uniform_(self.fc1.weight)\n",
    "        self.Act1 = torch.nn.functional.elu\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)  \n",
    "        xavier_uniform_(self.fc2.weight)\n",
    "        self.Act2 = torch.nn.functional.elu\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        xavier_uniform_(self.fc3.weight)\n",
    "        self.Act3 = Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.loc1(x)\n",
    "        out = self.ActLoc1(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.Act1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.Act2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.Act3(out)\n",
    "        return out\n",
    "        \n",
    "    def compute_l1_loss(self, w):\n",
    "        return torch.abs(w).sum()        \n",
    "    \n",
    "\n",
    "Model = NeuralNet(input_size, hidden_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss() # initialize loss function\n",
    "optimizer = torch.optim.Adam(Model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "grad_bank = {}\n",
    "avg_counter = 0\n",
    "num_ins = x3D_all2.shape[0]\n",
    "num_epochs = 40\n",
    "p_norm = 1\n",
    "l1_lambda = 0.00001\n",
    "Batch_counter = int(np.ceil(num_ins/batch_size))\n",
    "total_step = Batch_counter\n",
    "print(Batch_counter)\n",
    "for epoch in range(num_epochs):   \n",
    "    for step in range(Batch_counter):\n",
    "        print(\"The step is\", step+1, \"out of\", Batch_counter)\n",
    "        step1 = (step*batch_size)\n",
    "        if step == (Batch_counter-1):\n",
    "            step2 = num_ins\n",
    "        else: \n",
    "            step2 = (step+1)*batch_size\n",
    "        print(\"The step1 is\", step1, \"and step2 is\", step2, \"out of\",num_ins)\n",
    "        # Forward pass\n",
    "        X_batch = x3D_all2[step1:step2,].clone().requires_grad_(True)\n",
    "        outputs = Model(X_batch) #X_all2[step1:step2,]\n",
    "        outputs = torch.squeeze(outputs, 0)\n",
    "        print(\"The output size is\", outputs.shape)\n",
    "        loss = criterion(outputs, Y[step1:step2,])  \n",
    "        #regularity =  torch.norm(model.loc1.weight, p=p_norm)\n",
    "        #cost = loss + l1_lambda * regularity\n",
    "        \n",
    "      # Compute L1 loss component\n",
    "        l1_weight = 1.0\n",
    "        l1_parameters = []\n",
    "        for parameter in Model.parameters():\n",
    "            l1_parameters.append(parameter.view(-1))\n",
    "        l1 = l1_weight * Model.compute_l1_loss(torch.cat(l1_parameters))\n",
    "      \n",
    "      # Add L1 loss component\n",
    "        loss += l1        \n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        #for idx, param in enumerate(model.parameters()):\n",
    "         #   grad_bank[idx] += param.grad.data\n",
    "          #  avg_counter += 1        \n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "               .format(epoch+1, num_epochs, step+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "# evaluate the model\n",
    "yhat = model(x3D_all2)\n",
    "yhat = yhat.detach().numpy()\n",
    "yhat.shape\n",
    "actual = Y.numpy()\n",
    "actual = actual.reshape((len(actual), 1))\n",
    "# round to class values\n",
    "yhat = yhat.round()\n",
    "yhat = yhat.reshape((num_ins, 1))\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(Y, yhat)\n",
    "acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = nn.Parameter(torch.randn(1, 1, 2, 98, 1))\n",
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,c, h = X_batch.size()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = stride = 1\n",
    "\n",
    "kh = kernel_size\n",
    "print(kh)\n",
    "dh = stride\n",
    "print(dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_batch.unfold(1, kh, dh)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x.unsqueeze(1)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = (x2 * weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.sum([2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = nn.Parameter(torch.randn(1, 1, 1, 98, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, h = x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "Y = torch.from_numpy(Y)\n",
    "X_all2 = torch.from_numpy(X_all)\n",
    "X_all2.requires_grad=True\n",
    "type(X_all2)\n",
    "# Train the model\n",
    "grad_bank = {}\n",
    "avg_counter = 0\n",
    "num_ins = X_all2.shape[0]\n",
    "num_epochs = 40\n",
    "p_norm = 1\n",
    "l1_lambda = 0.00001\n",
    "Batch_counter = int(np.ceil(num_ins/batch_size))\n",
    "total_step = Batch_counter\n",
    "print(Batch_counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
